{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Categorization\n",
    "\n",
    "This notebook shows how to use LabelKit to categorize a list of products into a product taxonomy.\n",
    "\n",
    "We are given a list of product names from an e-commerce marketplace, like\n",
    "\n",
    "`Kitsch Velvet Scrunchies for Hair, Hair Scrunchies for Women, Scrunchy Hair Bands, 5 Pack (Blush/Mauve)`\n",
    "\n",
    "And some product categories in the form of a taxonomy, for example the category for the above product might be\n",
    "\n",
    "`Beauty > Hair Care > Hair Styling`\n",
    "\n",
    "The goal is to accurately map each product into the best category, given a taxonomy containing 1000+ categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "We'll implement the following multi-step approach:\n",
    "\n",
    "1. Do a google search on the product name\n",
    "\n",
    "2. Feed the name and the search results from Step 1 into an LLM to get a short product description\n",
    "\n",
    "3. Create embeddings of the product categories and store them in a vector store. Then do a nearest neighbor search with the product description created in Step 3.\n",
    "\n",
    "4. Feed the top N nearest neighbor categories along with the product description into an LLM and ask it to pick the best one\n",
    "\n",
    "# <p align=\"center\"><img src=\"image.png\" width=\"700\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies, import libraries, and load the data and the taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/hwln9nhn6tb990j17wgs638r0000gn/T/ipykernel_1896/1194329160.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# %pip install cohere\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from labelkit import *\n",
    "from pydantic import BaseModel, Field\n",
    "import cohere\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_csv('./taxonomy.csv').fillna(\"\")\n",
    "taxonomy = list(taxonomy['sector'] + \" > \" + taxonomy['department'] + \" > \" + taxonomy['major_category'])\n",
    "df = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Pipeline using LabelKit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the first step of the pipeline which uses a Google SERP library to search for the `description` field on the input object.\n",
    "\n",
    "We do this by using LabelKit's built-in `SERPEnrichmentStep`. You could also easily build your own using a `CustomStep` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(serp_result):\n",
    "  top_n = 5\n",
    "  short = []\n",
    "  y = json.loads(serp_result).get('organic')\n",
    "  if y is None:\n",
    "    return None\n",
    "  for o in y[:top_n]:\n",
    "    short.append({\n",
    "        'title': o['title'],\n",
    "        'snippet': o['snippet'],\n",
    "        'link': o['link']\n",
    "    })\n",
    "  return short\n",
    "\n",
    "serp_step = steps.SERPEnrichmentStep(\n",
    "  params={\n",
    "  \"prompt\": lambda row: row['description'], \n",
    "  \"postprocess\": shorten\n",
    "  }, \n",
    "  name=\"serp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step of the pipeline takes the product description and the search results and feeds them into an LLM to get a better description. We create this step using LabelKit's `LLMStep`.\n",
    "\n",
    "An `LLMStep` instance takes a Pydantic model and a prompt generator function as arguments. The pydantic model specifies the output structure (remember every `LLMStep` creates structured output). The prompt generator function defines how to generate a prompt from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_description_prompt = lambda row: f\"\"\"\n",
    "You are given a product description and a list of google search results about a product.\n",
    "Return a single sentence decribing the product.\n",
    "Product description: {row['description']}\n",
    "Search results:\n",
    "{row['serp']}\n",
    "\"\"\"\n",
    "\n",
    "class ShortDescription(BaseModel):\n",
    "  short_description: str = Field(description=\"A single sentence describing the product\")\n",
    "  \n",
    "short_description_step = steps.LLMStep(\n",
    "  params={\n",
    "    \"prompt\": short_description_prompt,\n",
    "    \"model\": models.gpt35\n",
    "  },\n",
    "  out_model=ShortDescription,\n",
    "  name=\"short_description\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the embedding classification step which creates a vector embedding from the taxonomy, and then finds the top 5 nearest neighbors for each input data point based on the short description generated in the previous step. \n",
    "\n",
    "We can use the built-in `EmbeddingClassificationStep` and provide it an `embed` function. You can use any embedding provider here. We use Cohere in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your cohere api key as an env var or set it directly here\n",
    "COHERE_API_KEY = os.environ.get('COHERE_API_KEY')\n",
    "co = cohere.Client(COHERE_API_KEY)\n",
    "\n",
    "def embed(texts: List[str]):\n",
    "  embeddings = co.embed(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    texts=texts,\n",
    "    input_type='classification'\n",
    "  ).embeddings\n",
    "  return np.array(embeddings).astype('float32')\n",
    "\n",
    "embedding_search_prompt = lambda row: row[\"short_description\"]\n",
    "\n",
    "embedding_search_step = steps.EmbeddingClassificationStep(\n",
    "  params={\n",
    "    \"search_prompt\": embedding_search_prompt,\n",
    "    \"embed\": embed,\n",
    "    \"k\": 5,    \n",
    "  },\n",
    "  categories=taxonomy,\n",
    "  name=\"embedding_search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we take the top 5 categories selected by the embedding step, feed them into an LLM query and ask it to pick the index of the best one. We use an `LLMStep` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorize_prompt(row):\n",
    "    categories = \"\"\n",
    "    i = 1\n",
    "    while f\"category{i}\" in row:\n",
    "        categories += f'{i}. {row[f\"category{i}\"]}\\n'\n",
    "        i += 1\n",
    "\n",
    "    return f\"\"\"\n",
    "    You are given a product description and {i-1} options for the product's category.\n",
    "    Pick the index of the most accurate category.\n",
    "    The index must be between 1 and {i-1}.\n",
    "    Product description: {row['short_description']}\n",
    "    Categories:\n",
    "    {categories}\n",
    "    \"\"\"\n",
    "    \n",
    "class CategoryIndex(BaseModel):\n",
    "    category_index: int = Field(description=\"The index of the most accurate category\")\n",
    "    \n",
    "categorize_step = steps.LLMStep(\n",
    "  params={\n",
    "    \"prompt\": categorize_prompt,\n",
    "    \"model\": models.gpt35\n",
    "  },\n",
    "  out_model=CategoryIndex,  \n",
    "  name=\"categorize\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous step output a category index but we want the actual category, so we need to map the index to the category. We'll create a simple `CustomStep` that simply grabs the `category{i}` field that was created in the embedding search step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category(BaseModel):\n",
    "    category: str = Field(description=\"The most accurate category\")\n",
    "\n",
    "select_category_step = steps.CustomStep(\n",
    "  params={\n",
    "    \"transform\": lambda row: {\"category\": row[f'category{row[\"category_index\"]}']}\n",
    "  },\n",
    "  out_model=Category,\n",
    "  name=\"select_category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done defining the steps. Finally, we define an evaluation function - a simple string comparison against the ground truth column which was present in the dataset. Then we define a LabelKit `Pipeline` and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = lambda row: row['category'].lower() == row['gpt4_category'].lower()\n",
    "\n",
    "categorizer = pipeline.Pipeline([\n",
    "  serp_step, \n",
    "  short_description_step, \n",
    "  embedding_search_step, \n",
    "  categorize_step,\n",
    "  select_category_step\n",
    "], evaluate)\n",
    "\n",
    "categorizer.apply(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating accuracy, token usage and latency\n",
    "\n",
    "LabelKit makes it easy to:\n",
    "\n",
    "- Evaluate the accuracy of your pipeline if your dataset has a ground truth column. If you passed in an `evaluate` function you can call `Pipeline.score` to get the accuracy score\n",
    "- Track the token usage and latency for each row or in aggregate over the entire dataset. To get the aggregate statistics, call `Pipeline.statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Statistics: {\"input_tokens\":{\"gpt-3.5-turbo-0125\":8114},\"output_tokens\":{\"gpt-3.5-turbo-0125\":557},\"num_success\":10,\"num_failure\":0,\"total_latency\":18.613963379291818}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {categorizer.score}\")\n",
    "print(f\"Statistics: {categorizer.statistics.model_dump_json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snappy-L-l7h_3B-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
